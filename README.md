
<img width="1598" height="1110" alt="730D836A-A570-487C-9748-179D835EC11E" src="https://github.com/user-attachments/assets/126055ff-b43b-49fa-8955-72edada783fa" />


<img width="2868" height="1626" alt="E04AD20A-46F5-49EC-8D59-C42DB0FBEFB0" src="https://github.com/user-attachments/assets/ac3ace21-cbfa-4298-bdf7-89a79b6b5458" />


<img width="2918" height="1350" alt="D0E03C16-E0C6-4FB4-A282-7DB13E84B701" src="https://github.com/user-attachments/assets/d6353e12-3461-41bb-ac25-8402f8861ed2" />
<img width="2934" height="952" alt="5EF2AAD7-72B0-4015-AA34-D3AF8D8E51DD" src="https://github.com/user-attachments/assets/12a19b1d-cc4c-4f7a-80ac-50f08f1e2227" />
![Uploading 1B67DD00-3817-48A0-BE7E-4695EE9D2C99.pngâ€¦]()




# ğŸ“Š Email Analytics Data Pipeline (Dagster + Docker)

This project demonstrates a **containerized, production-style data pipeline** that ingests email events, orchestrates processing with **Dagster**, and visualizes analytics in **Power BI**. It is designed as a **data engineering portfolio project** following real-world architecture patterns.

---

## ğŸ—ï¸ Architecture Overview

```
Email Source â†’ Dagster â†’ Data Warehouse â†’ Google Looker Studio
```

---

## ğŸ”§ Components Explained

### ğŸ“§ Email Source

* Gmail / Email API / mock CSV data
* Raw events: sent, opened, clicked, received

### ğŸ³ Docker (Infrastructure Layer)

* All services run inside containers
* Ensures reproducibility and easy local setup
* Single command startup using docker-compose

### ğŸ§  Dagster (Orchestration Layer)

* Defines **assets, jobs, and schedules**
* Handles orchestration, retries, and dependencies
* Manages backfills and partitioned data
* Produces clean, validated datasets

### ğŸ—„ï¸ Data Warehouse

* Postgres / BigQuery / Snowflake
* Stores transformed and analytics-ready data
* Partitioned by date for performance

### ğŸ“ˆ Power BI (Visualization)

* Connects directly to the warehouse
* Used for dashboards and reporting
* Auto-refresh enabled

---

## ğŸ”„ Data Flow

1. **Ingest**

   * Email events collected from source

2. **Process & Orchestrate (Dagster)**

   * Schema validation
   * Data cleaning & transformation
   * Asset materialization
   * Scheduling & backfills

3. **Load**

   * Clean data written to warehouse
   * Partitioned by date

4. **Visualize**

   * Power BI dashboards update automatically

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ dagster/              # Dagster assets, jobs, schedules
â”œâ”€â”€ scripts/              # ETL logic
â”œâ”€â”€ data/                 # Sample datasets
â”œâ”€â”€ docker-compose.yml    # All services
â”œâ”€â”€ Dockerfile            # Custom Dagster image
â””â”€â”€ README.md
```

---

## ğŸ³ Run Locally

```bash
docker-compose up -d
```

### Access Services

* Dagster UI: [http://localhost:3000](http://localhost:3000)
* Warehouse: localhost:5432

---

## âš™ï¸ Example Pipeline

```text
extract_email_data â†’ transform_email_data â†’ load_to_warehouse
```

---

## ğŸ“Š Example Analytics

* Email volume per day
* Open and click rates
* Processing latency
* Daily trends and spikes

---

## ğŸ§ª Testing Strategy

* Multiple day CSV datasets (backfill testing)
* Partitioned assets (daily)
* Idempotent runs
* Late-arriving data simulation
* Schema drift handling

---

## ğŸ¯ Skills Demonstrated

* Dagster orchestration (assets, schedules, sensors)
* Docker & containerization
* ETL / ELT best practices
* Partitioned data modeling
* Analytics engineering
* BI integration (Power BI)

---

## ğŸ‘¤ Author

**Ian Tristan**
Aspiring Data Engineer | Dagster | Docker | Analytics

---







